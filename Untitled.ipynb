{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection,svm,naive_bayes\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index UserName ScreenName   Location     TweetAt  \\\n",
       "0      1     3799      48751     London  16-03-2020   \n",
       "1      2     3800      48752         UK  16-03-2020   \n",
       "2      3     3801      48753  Vagabonds  16-03-2020   \n",
       "3      4     3802      48754        NaN  16-03-2020   \n",
       "4      5     3803      48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Corona_NLP_train.csv\", encoding =\"ISO-8859-1\" , names=[\"UserName\", \"ScreenName\", \"Location\", \"TweetAt\", \"OriginalTweet\", \"Sentiment\"])\n",
    "df.drop(0,inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=[\"index\",\"UserName\", \"ScreenName\", \"Location\", \"TweetAt\"])\n",
    "#df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>Airline pilots offering to stock supermarket s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>Response to complaint not provided citing COVI...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>You know itÂs getting tough when @KameronWild...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "0      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...       1\n",
       "1      advice Talk to your neighbours family to excha...       2\n",
       "2      Coronavirus Australia: Woolworths to give elde...       2\n",
       "3      My food stock is not the only one which is emp...       2\n",
       "4      Me, ready to go at supermarket during the #COV...       0\n",
       "...                                                  ...     ...\n",
       "41152  Airline pilots offering to stock supermarket s...       1\n",
       "41153  Response to complaint not provided citing COVI...       0\n",
       "41154  You know itÂs getting tough when @KameronWild...       2\n",
       "41155  Is it wrong that the smell of hand sanitizer i...       1\n",
       "41156  @TartiiCat Well new/used Rift S are going for ...       0\n",
       "\n",
       "[41157 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"]=df[\"Sentiment\"].replace({'Extremely Negative':0,'Negative':0,'Neutral':1,'Positive':2,'Extremely Positive':2})\n",
    "df.columns=[\"\",\"text\",\"target\"]\n",
    "df.drop(\"\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    18046\n",
       "0    15398\n",
       "1     7713\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index                                                      text  target\n",
      "20152  41152  41152  Airline pilots offering to stock supermarket s...       1\n",
      "20153  41153  41153  Response to complaint not provided citing COVI...       0\n",
      "20154  41154  41154  You know itÂs getting tough when @KameronWild...       2\n",
      "20155  41155  41155  Is it wrong that the smell of hand sanitizer i...       1\n",
      "20156  41156  41156  @TartiiCat Well new/used Rift S are going for ...       0\n"
     ]
    }
   ],
   "source": [
    "a=0\n",
    "b=0\n",
    "c=0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if(row['target']==0 and a<7000):  \n",
    "        df.drop(index=index,inplace=True)\n",
    "        a=a+1   \n",
    "    elif(row['target']==1 and b<7000):  \n",
    "        df.drop(index=index,inplace=True)\n",
    "        b=b+1\n",
    "    elif(row['target']==2 and c<7000): \n",
    "        df.drop(index=index,inplace=True)\n",
    "        c=c+1\n",
    "    if(a >=7000 and b>=7000 and c>=7000):\n",
    "        break;\n",
    "df2.reset_index(inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "print(df.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels=['index'],axis=1,inplace=True)\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Louis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Louis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Louis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Louis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text']=[word_tokenize(entry.lower()) for entry in df['text'].dropna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33089</td>\n",
       "      <td>33089</td>\n",
       "      <td>Due to the rapid spread of Covid-19 the CDC ad...</td>\n",
       "      <td>0</td>\n",
       "      <td>[due, to, the, rapid, spread, of, covid-19, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35412</td>\n",
       "      <td>35412</td>\n",
       "      <td>Coronavirus Stimulus Fraud May Be A Target For...</td>\n",
       "      <td>0</td>\n",
       "      <td>[coronavirus, stimulus, fraud, may, be, a, tar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28895</td>\n",
       "      <td>28895</td>\n",
       "      <td>Friend in Alabama went to grocery store He tel...</td>\n",
       "      <td>2</td>\n",
       "      <td>[friend, in, alabama, went, to, grocery, store...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26089</td>\n",
       "      <td>26089</td>\n",
       "      <td>? NJ CORPORATE DONATIONS\\r\\r\\n?? @FirstEnergy ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[?, nj, corporate, donations, ?, ?, @, firsten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37328</td>\n",
       "      <td>37328</td>\n",
       "      <td>@MaximeBernier During a time when there has be...</td>\n",
       "      <td>0</td>\n",
       "      <td>[@, maximebernier, during, a, time, when, ther...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                                      text  target  \\\n",
       "0  33089  33089  Due to the rapid spread of Covid-19 the CDC ad...       0   \n",
       "1  35412  35412  Coronavirus Stimulus Fraud May Be A Target For...       0   \n",
       "2  28895  28895  Friend in Alabama went to grocery store He tel...       2   \n",
       "3  26089  26089  ? NJ CORPORATE DONATIONS\\r\\r\\n?? @FirstEnergy ...       2   \n",
       "4  37328  37328  @MaximeBernier During a time when there has be...       0   \n",
       "\n",
       "                                                Text  \n",
       "0  [due, to, the, rapid, spread, of, covid-19, th...  \n",
       "1  [coronavirus, stimulus, fraud, may, be, a, tar...  \n",
       "2  [friend, in, alabama, went, to, grocery, store...  \n",
       "3  [?, nj, corporate, donations, ?, ?, @, firsten...  \n",
       "4  [@, maximebernier, during, a, time, when, ther...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>Text</th>\n",
       "      <th>text_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33089</td>\n",
       "      <td>33089</td>\n",
       "      <td>Due to the rapid spread of Covid-19 the CDC ad...</td>\n",
       "      <td>0</td>\n",
       "      <td>[due, to, the, rapid, spread, of, covid-19, th...</td>\n",
       "      <td>['due', 'rapid', 'spread', 'cdc', 'advise', 'e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35412</td>\n",
       "      <td>35412</td>\n",
       "      <td>Coronavirus Stimulus Fraud May Be A Target For...</td>\n",
       "      <td>0</td>\n",
       "      <td>[coronavirus, stimulus, fraud, may, be, a, tar...</td>\n",
       "      <td>['coronavirus', 'stimulus', 'fraud', 'may', 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28895</td>\n",
       "      <td>28895</td>\n",
       "      <td>Friend in Alabama went to grocery store He tel...</td>\n",
       "      <td>2</td>\n",
       "      <td>[friend, in, alabama, went, to, grocery, store...</td>\n",
       "      <td>['friend', 'alabama', 'go', 'grocery', 'store'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26089</td>\n",
       "      <td>26089</td>\n",
       "      <td>? NJ CORPORATE DONATIONS\\r\\r\\n?? @FirstEnergy ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[?, nj, corporate, donations, ?, ?, @, firsten...</td>\n",
       "      <td>['nj', 'corporate', 'donation', 'firstenergy',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37328</td>\n",
       "      <td>37328</td>\n",
       "      <td>@MaximeBernier During a time when there has be...</td>\n",
       "      <td>0</td>\n",
       "      <td>[@, maximebernier, during, a, time, when, ther...</td>\n",
       "      <td>['maximebernier', 'time', 'unprecedented', 'dr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                                      text  target  \\\n",
       "0  33089  33089  Due to the rapid spread of Covid-19 the CDC ad...       0   \n",
       "1  35412  35412  Coronavirus Stimulus Fraud May Be A Target For...       0   \n",
       "2  28895  28895  Friend in Alabama went to grocery store He tel...       2   \n",
       "3  26089  26089  ? NJ CORPORATE DONATIONS\\r\\r\\n?? @FirstEnergy ...       2   \n",
       "4  37328  37328  @MaximeBernier During a time when there has be...       0   \n",
       "\n",
       "                                                Text  \\\n",
       "0  [due, to, the, rapid, spread, of, covid-19, th...   \n",
       "1  [coronavirus, stimulus, fraud, may, be, a, tar...   \n",
       "2  [friend, in, alabama, went, to, grocery, store...   \n",
       "3  [?, nj, corporate, donations, ?, ?, @, firsten...   \n",
       "4  [@, maximebernier, during, a, time, when, ther...   \n",
       "\n",
       "                                          text_final  \n",
       "0  ['due', 'rapid', 'spread', 'cdc', 'advise', 'e...  \n",
       "1  ['coronavirus', 'stimulus', 'fraud', 'may', 't...  \n",
       "2  ['friend', 'alabama', 'go', 'grocery', 'store'...  \n",
       "3  ['nj', 'corporate', 'donation', 'firstenergy',...  \n",
       "4  ['maximebernier', 'time', 'unprecedented', 'dr...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "word_lemmatized = WordNetLemmatizer()\n",
    "\n",
    "for index,entry in enumerate(df['Text']):\n",
    "    if(index%1000==0):\n",
    "        print(index)\n",
    "    final_words= []\n",
    "    \n",
    "    for word,tag in pos_tag(entry):\n",
    "        if word not in stopwords.words(\"english\") and word.isalpha():\n",
    "            final_words.append(word_lemmatized.lemmatize(word,tag_map[tag[0]]))\n",
    "    \n",
    "    df.loc[index,'text_final']= str(final_words)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"lemmatized_data_reduced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y = model_selection.train_test_split(df['text_final'],df['target'],test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "train_y_encoded = encoder.fit_transform(train_y)\n",
    "test_y_encoded = encoder.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform tfidf vectorization on your data\n",
    "tfidf_vect = TfidfVectorizer(sublinear_tf=True)\n",
    "tfidf_vect.fit(df['text_final'])\n",
    "train_x_tfidf = tfidf_vect.transform(train_x)\n",
    "test_x_tfidf = tfidf_vect.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=3, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM=svm.SVC(C=3,kernel='linear',degree=3,gamma='auto')\n",
    "SVM.fit(train_x_tfidf,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_SVM=SVM.predict(test_x_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score:  0.8192791005291006\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Accuracy Score: \",accuracy_score(predictions_SVM,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy score:  0.7166005291005291\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the Naive Bayes classifier\n",
    "naive = naive_bayes.MultinomialNB(alpha=0.02)\n",
    "naive.fit(train_x_tfidf,train_y_encoded)\n",
    "#predit the labels on validation dataset\n",
    "predictions_NB = naive.predict(test_x_tfidf)\n",
    "#Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy score: \",accuracy_score(predictions_NB,test_y_encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy Score:  0.777281746031746\n"
     ]
    }
   ],
   "source": [
    "#fit using random forest \n",
    "clf=RandomForestClassifier()\n",
    "clf.fit(train_x_tfidf,train_y)\n",
    "predictions_RF = clf.predict(test_x_tfidf)\n",
    "print(\"RF Accuracy Score: \",accuracy_score(predictions_RF,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(SVM,\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
