{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection,svm,naive_bayes\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index UserName ScreenName   Location     TweetAt  \\\n",
       "0      1     3799      48751     London  16-03-2020   \n",
       "1      2     3800      48752         UK  16-03-2020   \n",
       "2      3     3801      48753  Vagabonds  16-03-2020   \n",
       "3      4     3802      48754        NaN  16-03-2020   \n",
       "4      5     3803      48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Corona_NLP_train.csv\", encoding =\"ISO-8859-1\" , names=[\"UserName\", \"ScreenName\", \"Location\", \"TweetAt\", \"OriginalTweet\", \"Sentiment\"])\n",
    "df.drop(0,inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=[\"index\",\"UserName\", \"ScreenName\", \"Location\", \"TweetAt\"])\n",
    "#df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>Airline pilots offering to stock supermarket s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>Response to complaint not provided citing COVI...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>You know itÂs getting tough when @KameronWild...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "0      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...       1\n",
       "1      advice Talk to your neighbours family to excha...       2\n",
       "2      Coronavirus Australia: Woolworths to give elde...       2\n",
       "3      My food stock is not the only one which is emp...       2\n",
       "4      Me, ready to go at supermarket during the #COV...       0\n",
       "...                                                  ...     ...\n",
       "41152  Airline pilots offering to stock supermarket s...       1\n",
       "41153  Response to complaint not provided citing COVI...       0\n",
       "41154  You know itÂs getting tough when @KameronWild...       2\n",
       "41155  Is it wrong that the smell of hand sanitizer i...       1\n",
       "41156  @TartiiCat Well new/used Rift S are going for ...       0\n",
       "\n",
       "[41157 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"]=df[\"Sentiment\"].replace({'Extremely Negative':0,'Negative':0,'Neutral':1,'Positive':2,'Extremely Positive':2})\n",
    "df.columns=[\"\",\"text\",\"target\"]\n",
    "df.drop(\"\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    18046\n",
       "0    15398\n",
       "1     7713\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index                                                      text  target\n",
      "5439  41150  41150  I never that weÂd be in a situation &amp; wor...       2\n",
      "5440  41151  41151  @MrSilverScott you are definitely my man. I fe...       2\n",
      "5441  41153  41153  Response to complaint not provided citing COVI...       0\n",
      "5442  41154  41154  You know itÂs getting tough when @KameronWild...       2\n",
      "5443  41156  41156  @TartiiCat Well new/used Rift S are going for ...       0\n"
     ]
    }
   ],
   "source": [
    "a=0\n",
    "b=0\n",
    "c=0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if(row['target']==0 and a<7000):  \n",
    "        df.drop(index=index,inplace=True)\n",
    "        a=a+1   \n",
    "    elif(row['target']==1 and b<7000):  \n",
    "        df.drop(index=index,inplace=True)\n",
    "        b=b+1\n",
    "    elif(row['target']==2 and c<7000): \n",
    "        df.drop(index=index,inplace=True)\n",
    "        c=c+1\n",
    "    if(a >=7000 and b>=7000 and c>=7000):\n",
    "        break;\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "print(df.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels=['index'],axis=1,inplace=True)\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Louis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Louis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Louis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Louis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text']=[word_tokenize(entry.lower()) for entry in df['text'].dropna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40953</td>\n",
       "      <td>We understand that this may be a challenging t...</td>\n",
       "      <td>2</td>\n",
       "      <td>[we, understand, that, this, may, be, a, chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33563</td>\n",
       "      <td>What s the safest way to shop at the grocery s...</td>\n",
       "      <td>2</td>\n",
       "      <td>[what, s, the, safest, way, to, shop, at, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33028</td>\n",
       "      <td>#CoronaVirusCanada\\r\\r\\nWorth emulating: execu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[#, coronaviruscanada, worth, emulating, :, ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35157</td>\n",
       "      <td>With this covid 19 from China,  Ghanaians are ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[with, this, covid, 19, from, china, ,, ghanai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41008</td>\n",
       "      <td>Endless gratitude to the grocery store workers...</td>\n",
       "      <td>2</td>\n",
       "      <td>[endless, gratitude, to, the, grocery, store, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       text  target  \\\n",
       "0  40953  We understand that this may be a challenging t...       2   \n",
       "1  33563  What s the safest way to shop at the grocery s...       2   \n",
       "2  33028  #CoronaVirusCanada\\r\\r\\nWorth emulating: execu...       2   \n",
       "3  35157  With this covid 19 from China,  Ghanaians are ...       2   \n",
       "4  41008  Endless gratitude to the grocery store workers...       2   \n",
       "\n",
       "                                                Text  \n",
       "0  [we, understand, that, this, may, be, a, chall...  \n",
       "1  [what, s, the, safest, way, to, shop, at, the,...  \n",
       "2  [#, coronaviruscanada, worth, emulating, :, ex...  \n",
       "3  [with, this, covid, 19, from, china, ,, ghanai...  \n",
       "4  [endless, gratitude, to, the, grocery, store, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>Text</th>\n",
       "      <th>text_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40953</td>\n",
       "      <td>We understand that this may be a challenging t...</td>\n",
       "      <td>2</td>\n",
       "      <td>[we, understand, that, this, may, be, a, chall...</td>\n",
       "      <td>['understand', 'may', 'challenging', 'time', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33563</td>\n",
       "      <td>What s the safest way to shop at the grocery s...</td>\n",
       "      <td>2</td>\n",
       "      <td>[what, s, the, safest, way, to, shop, at, the,...</td>\n",
       "      <td>['safe', 'way', 'shop', 'grocery', 'store', 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33028</td>\n",
       "      <td>#CoronaVirusCanada\\r\\r\\nWorth emulating: execu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[#, coronaviruscanada, worth, emulating, :, ex...</td>\n",
       "      <td>['coronaviruscanada', 'worth', 'emulate', 'exe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35157</td>\n",
       "      <td>With this covid 19 from China,  Ghanaians are ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[with, this, covid, 19, from, china, ,, ghanai...</td>\n",
       "      <td>['covid', 'china', 'ghanaians', 'step', 'make'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41008</td>\n",
       "      <td>Endless gratitude to the grocery store workers...</td>\n",
       "      <td>2</td>\n",
       "      <td>[endless, gratitude, to, the, grocery, store, ...</td>\n",
       "      <td>['endless', 'gratitude', 'grocery', 'store', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       text  target  \\\n",
       "0  40953  We understand that this may be a challenging t...       2   \n",
       "1  33563  What s the safest way to shop at the grocery s...       2   \n",
       "2  33028  #CoronaVirusCanada\\r\\r\\nWorth emulating: execu...       2   \n",
       "3  35157  With this covid 19 from China,  Ghanaians are ...       2   \n",
       "4  41008  Endless gratitude to the grocery store workers...       2   \n",
       "\n",
       "                                                Text  \\\n",
       "0  [we, understand, that, this, may, be, a, chall...   \n",
       "1  [what, s, the, safest, way, to, shop, at, the,...   \n",
       "2  [#, coronaviruscanada, worth, emulating, :, ex...   \n",
       "3  [with, this, covid, 19, from, china, ,, ghanai...   \n",
       "4  [endless, gratitude, to, the, grocery, store, ...   \n",
       "\n",
       "                                          text_final  \n",
       "0  ['understand', 'may', 'challenging', 'time', '...  \n",
       "1  ['safe', 'way', 'shop', 'grocery', 'store', 's...  \n",
       "2  ['coronaviruscanada', 'worth', 'emulate', 'exe...  \n",
       "3  ['covid', 'china', 'ghanaians', 'step', 'make'...  \n",
       "4  ['endless', 'gratitude', 'grocery', 'store', '...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "word_lemmatized = WordNetLemmatizer()\n",
    "\n",
    "for index,entry in enumerate(df['Text']):\n",
    "    if(index%1000==0):\n",
    "        print(index)\n",
    "    final_words= []\n",
    "    \n",
    "    for word,tag in pos_tag(entry):\n",
    "        if word not in stopwords.words(\"english\") and word.isalpha() and \"corona\" not in word:\n",
    "            final_words.append(word_lemmatized.lemmatize(word,tag_map[tag[0]]))\n",
    "    \n",
    "    df.loc[index,'text_final']= str(final_words)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"lemmatized_data_reduced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y = model_selection.train_test_split(df['text_final'],df['target'],test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "train_y_encoded = encoder.fit_transform(train_y)\n",
    "test_y_encoded = encoder.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform tfidf vectorization on your data\n",
    "tfidf_vect = TfidfVectorizer(sublinear_tf=True)\n",
    "tfidf_vect.fit(df['text_final'])\n",
    "train_x_tfidf = tfidf_vect.transform(train_x)\n",
    "test_x_tfidf = tfidf_vect.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=3, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM=svm.SVC(C=3,kernel='linear',degree=3,gamma='auto')\n",
    "SVM.fit(train_x_tfidf,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_SVM=SVM.predict(test_x_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score:  0.8482252141982864\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Accuracy Score: \",accuracy_score(predictions_SVM,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the training dataset on the Naive Bayes classifier\n",
    "naive = naive_bayes.MultinomialNB(alpha=0.02)\n",
    "naive.fit(train_x_tfidf,train_y_encoded)\n",
    "#predit the labels on validation dataset\n",
    "predictions_NB = naive.predict(test_x_tfidf)\n",
    "#Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy score: \",accuracy_score(predictions_NB,test_y_encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit using random forest \n",
    "clf=RandomForestClassifier()\n",
    "clf.fit(train_x_tfidf,train_y)\n",
    "predictions_RF = clf.predict(test_x_tfidf)\n",
    "print(\"RF Accuracy Score: \",accuracy_score(predictions_RF,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(SVM,\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM.predict(tfidf_vect.transform([sentence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
